{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importando as bibliotecas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer #loving = love\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/hugo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloading stopwords\n",
    "\n",
    "nltk.download('stopwords') # stopwords são preposições, 'this', 'that',..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame.from_csv('train.tsv', sep='\\t')\n",
    "test = pd.DataFrame.from_csv('test.tsv', sep='\\t')\n",
    "y_train = train['Sentiment']\n",
    "PhraseId = test.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhraseId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>of escapades demonstrating the adage that what...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>escapades demonstrating the adage that what is...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating the adage that what is good for ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SentenceId                                             Phrase  \\\n",
       "PhraseId                                                                  \n",
       "1                  1  A series of escapades demonstrating the adage ...   \n",
       "2                  1  A series of escapades demonstrating the adage ...   \n",
       "3                  1                                           A series   \n",
       "4                  1                                                  A   \n",
       "5                  1                                             series   \n",
       "6                  1  of escapades demonstrating the adage that what...   \n",
       "7                  1                                                 of   \n",
       "8                  1  escapades demonstrating the adage that what is...   \n",
       "9                  1                                          escapades   \n",
       "10                 1  demonstrating the adage that what is good for ...   \n",
       "\n",
       "          Sentiment  \n",
       "PhraseId             \n",
       "1                 1  \n",
       "2                 2  \n",
       "3                 2  \n",
       "4                 2  \n",
       "5                 2  \n",
       "6                 2  \n",
       "7                 2  \n",
       "8                 2  \n",
       "9                 2  \n",
       "10                2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .',\n",
       "       'A series of escapades demonstrating the adage that what is good for the goose',\n",
       "       'A series', 'A', 'series',\n",
       "       'of escapades demonstrating the adage that what is good for the goose',\n",
       "       'of',\n",
       "       'escapades demonstrating the adage that what is good for the goose',\n",
       "       'escapades',\n",
       "       'demonstrating the adage that what is good for the goose'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.iloc[:, 1].values\n",
    "X_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus for training set\n",
    "corpus = [] # Initializing an empty list\n",
    "for i in range(0, len(train)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', train.iloc[i, 1]) # Replacing non letters with empty spaces\n",
    "    review = review.lower() # Getting lowers\n",
    "    review = review.split() # Splitting on spaces - creating a vector\n",
    "    ps = PorterStemmer() \n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))] # Iterating over vector excluding stopwords\n",
    "    review = ' '.join(review) # to string\n",
    "    corpus.append(review) # append on corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(corpus).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seri escapad demonstr adag good goos',\n",
       " 'seri',\n",
       " '',\n",
       " 'seri',\n",
       " 'escapad demonstr adag good goos',\n",
       " '',\n",
       " 'escapad demonstr adag good goos',\n",
       " 'escapad',\n",
       " 'demonstr adag good goos']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the bag of words model and vectorizing\n",
    "cv = CountVectorizer(max_features = 1500) \n",
    "X_train = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 1500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus for test set\n",
    "\n",
    "corpus_test = [] # Initializing an empty list\n",
    "for i in range(0, len(test)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', test.iloc[i, 1]) # Replacing non letters with empty spaces\n",
    "    review = review.lower() # Getting lowers\n",
    "    review = review.split() # Splitting on spaces - creating a vector\n",
    "    ps = PorterStemmer() \n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))] # Iterating over vector excluding stopwords\n",
    "    review = ' '.join(review) # to string\n",
    "    corpus_test.append(review) # append on corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66292,)\n",
      "['intermitt pleas mostli routin effort', 'intermitt pleas mostli routin effort', '', 'intermitt pleas mostli routin effort', 'intermitt pleas mostli routin', 'intermitt pleas', 'intermitt pleas', 'intermitt', 'pleas', '']\n"
     ]
    }
   ],
   "source": [
    "print(np.array(corpus_test).shape)\n",
    "print(corpus_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the bag of words model and vectorizing\n",
    "cv = CountVectorizer(max_features = 1500) \n",
    "X_test = cv.fit_transform(corpus_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66292, 1500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definning params for classifiers\n",
    "\n",
    "params_rf = {'n_estimators': 100,\n",
    "             'criterion': 'entropy',\n",
    "             'n_jobs': 2,\n",
    "             'random_state': 42,\n",
    "             'verbose': 2\n",
    "}\n",
    "\n",
    "params_etc = {'n_estimators': 100,\n",
    "              'criterion': 'entropy',\n",
    "              'max_depth': None,\n",
    "              'min_samples_split': 2,\n",
    "              'min_samples_leaf': 1,\n",
    "              'n_jobs': 2,\n",
    "              'random_state': 42,\n",
    "              'verbose': 2\n",
    "}\n",
    "\n",
    "params_ada = {'n_estimators': 100,\n",
    "              'learning_rate': 1,\n",
    "              'random_state': 42,\n",
    "             }\n",
    "\n",
    "params_gtb = {'loss': 'deviance',\n",
    "              'learning_rate': 1,\n",
    "              'n_estimators': 100,\n",
    "              'random_state': 42,\n",
    "              'verbose': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the classifiers\n",
    "clf_rf = RandomForestClassifier(**params_rf)\n",
    "clf_etc = ExtraTreesClassifier(**params_etc)\n",
    "clf_ada = AdaBoostClassifier(**params_ada)\n",
    "clf_gtb = GradientBoostingClassifier(**params_gtb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100building tree 2 of 100\n",
      "\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 13.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed: 34.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=2, oob_score=False, random_state=42,\n",
       "            verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the classifiers\n",
    "clf_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100\n",
      "building tree 1 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 10.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed: 28.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=2, oob_score=False, random_state=42,\n",
       "           verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_etc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
       "          n_estimators=100, random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ada.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      198355.8416          106.25m\n",
      "         2      194342.9795           89.97m\n",
      "         3      192879.7697           84.02m\n",
      "         4      192112.5930           80.58m\n",
      "         5      194134.6902           78.23m\n",
      "         6 145881052654.5818           76.78m\n",
      "         7 23660709933723.9492           75.27m\n",
      "         8 23662450644206.6133           73.89m\n",
      "         9 23662450644346.7852           72.63m\n",
      "        10 23937226108178.2109           71.43m\n",
      "        11 23937226107654.5000           70.17m\n",
      "        12 23937226102165.3711           68.99m\n",
      "        13 23937226101661.3438           68.01m\n",
      "        14 23937226101263.6406           67.06m\n",
      "        15 23937226100948.9297           66.12m\n",
      "        16 23937226100539.7656           65.23m\n",
      "        17 23937226100188.0547           64.34m\n",
      "        18 23937226099798.1367           63.48m\n",
      "        19 23937226099381.9141           62.64m\n",
      "        20 23937226099075.5430           61.79m\n",
      "        21 23937226098745.4414           60.94m\n",
      "        22 23937226098425.7578           60.11m\n",
      "        23 23937226098115.0273           59.29m\n",
      "        24 23937226097858.5547           58.48m\n",
      "        25 23937226097809.2695           57.67m\n",
      "        26 23937228163663.6094           56.87m\n",
      "        27 23937246582812.5273           56.01m\n",
      "        28 23937246582616.1055           55.14m\n",
      "        29 23937246582439.0781           54.30m\n",
      "        30 23937246582263.4492           53.50m\n",
      "        31 23937246582083.9531           52.67m\n",
      "        32 23937246581935.4648           51.87m\n",
      "        33 23937246581748.5156           51.11m\n",
      "        34 86290560413184.1562           50.35m\n",
      "        35 86290560413055.4375           49.57m\n",
      "        36 86290560412923.7969           48.79m\n",
      "        37 86290560412800.7031           48.01m\n",
      "        38 86290560412692.5781           47.24m\n",
      "        39 86290560412548.2812           46.47m\n",
      "        40 86290560412426.9375           45.64m\n",
      "        41 86290560412303.8594           44.82m\n",
      "        42 86290560412188.6406           44.01m\n",
      "        43 86290560412053.7031           43.20m\n",
      "        44 86290560411939.3281           42.39m\n",
      "        45 86290560411862.0625           41.59m\n",
      "        46 86290560411781.0938           40.79m\n",
      "        47 86290560411707.2812           40.00m\n",
      "        48 86290560411632.5000           39.21m\n",
      "        49 86290560411555.0469           38.42m\n",
      "        50 86290560411474.5781           37.64m\n",
      "        51 86290560411395.0312           36.85m\n",
      "        52 86290560411319.5469           36.07m\n",
      "        53 86290560411246.8125           35.30m\n",
      "        54 86290560411166.5938           34.54m\n",
      "        55 86290560411095.0781           33.79m\n",
      "        56 86290560411025.5156           33.04m\n",
      "        57 86290560410948.1719           32.29m\n",
      "        58 86290560410879.9688           31.55m\n",
      "        59 86290560410808.2344           30.80m\n",
      "        60 86290560410745.4219           30.05m\n",
      "        61 86290560410677.8125           29.30m\n",
      "        62 86290560410610.4531           28.55m\n",
      "        63 86290560410546.7344           27.80m\n",
      "        64 86290560410477.7344           27.04m\n",
      "        65 86290560410411.3438           26.27m\n",
      "        66 86290560410344.2969           25.50m\n",
      "        67 86290560410281.8281           24.73m\n",
      "        68 86290560410221.9219           23.96m\n",
      "        69 86290560410144.3125           23.20m\n",
      "        70 86290560410082.3906           22.44m\n",
      "        71 86290560410018.5938           21.67m\n",
      "        72 86290560409959.0938           20.91m\n",
      "        73 86290560409895.8906           20.16m\n",
      "        74 86290560409839.4219           19.40m\n",
      "        75 86290560409778.4844           18.64m\n",
      "        76 86290560409711.1875           17.89m\n",
      "        77 86290560409643.8125           17.13m\n",
      "        78 86290560409584.5000           16.38m\n",
      "        79 86290560409529.5156           15.63m\n",
      "        80 86290560409477.5312           14.87m\n",
      "        81 86290560409416.9688           14.13m\n",
      "        82 86290560409309.2969           13.37m\n",
      "        83 86290560409245.5156           12.62m\n",
      "        84 86290560409191.5625           11.87m\n",
      "        85 86290560409136.9531           11.12m\n",
      "        86 86290560409099.8594           10.38m\n",
      "        87 86290560409066.4219            9.63m\n",
      "        88 86290560409032.6562            8.89m\n",
      "        89 86290560408997.8281            8.14m\n",
      "        90 86290560409000.0625            7.40m\n",
      "        91 86290560408968.4531            6.66m\n",
      "        92 86290560408936.7812            5.92m\n",
      "        93 86290560408872.8594            5.17m\n",
      "        94 86290560408838.3281            4.43m\n",
      "        95 86290560408803.8281            3.69m\n",
      "        96 86290560408771.6875            2.95m\n",
      "        97 86290560408740.1406            2.21m\n",
      "        98 86290560408707.8281            1.48m\n",
      "        99 86290560408677.2656           44.27s\n",
      "       100 86290560408644.2031            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=42,\n",
       "              subsample=1.0, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gtb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   28.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Random Forest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.58      0.67      7072\n",
      "          1       0.76      0.59      0.67     27273\n",
      "          2       0.77      0.92      0.84     79582\n",
      "          3       0.77      0.65      0.70     32927\n",
      "          4       0.79      0.64      0.71      9206\n",
      "\n",
      "avg / total       0.77      0.77      0.76    156060\n",
      "\n",
      "\n",
      "Classification report for Extra Trees Classifier\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.71      0.70      7072\n",
      "          1       0.74      0.63      0.68     27273\n",
      "          2       0.77      0.91      0.84     79582\n",
      "          3       0.79      0.62      0.70     32927\n",
      "          4       0.88      0.56      0.68      9206\n",
      "\n",
      "avg / total       0.77      0.77      0.76    156060\n",
      "\n",
      "\n",
      "Classification report for Ada Boosting\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      0.11      0.18      7072\n",
      "          1       0.46      0.11      0.18     27273\n",
      "          2       0.58      0.93      0.72     79582\n",
      "          3       0.45      0.25      0.32     32927\n",
      "          4       0.48      0.14      0.21      9206\n",
      "\n",
      "avg / total       0.52      0.56      0.48    156060\n",
      "\n",
      "\n",
      "Classification report for Gradient Tree Boosting\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.06      0.11      7072\n",
      "          1       0.48      0.18      0.26     27273\n",
      "          2       0.61      0.93      0.73     79582\n",
      "          3       0.46      0.28      0.34     32927\n",
      "          4       0.44      0.14      0.22      9206\n",
      "\n",
      "avg / total       0.54      0.57      0.51    156060\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicting on training set\n",
    "y_pred_RF = clf_rf.predict(X_train)\n",
    "y_pred_etc = clf_etc.predict(X_train)\n",
    "y_pred_ada = clf_ada.predict(X_train)\n",
    "y_pred_gtb = clf_gtb.predict(X_train)\n",
    "\n",
    "print(\"Classification report for Random Forest\")\n",
    "print(classification_report(y_train, y_pred_RF))\n",
    "print()\n",
    "\n",
    "print(\"Classification report for Extra Trees Classifier\")\n",
    "print(classification_report(y_train, y_pred_etc))\n",
    "print()\n",
    "\n",
    "print(\"Classification report for Ada Boosting\")\n",
    "print(classification_report(y_train, y_pred_ada))\n",
    "print()\n",
    "\n",
    "print(\"Classification report for Gradient Tree Boosting\")\n",
    "print(classification_report(y_train, y_pred_gtb))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD8CAYAAAC8TPVwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f53e760c208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Printing confusion matrix for the best model based on accuracy\n",
    "cm = confusion_matrix(y, y_pred_train)\n",
    "\n",
    "sns.heatmap(data = cm, annot= True, fmt='.1f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   10.0s finished\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   10.1s finished\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({\"PhraseId\": PhraseId, \"Sentiment\": clf_rf.predict(X_test)}).to_csv(\"./results/results_rf.csv\", index=None)\n",
    "pd.DataFrame({\"PhraseId\": PhraseId, \"Sentiment\": clf_etc.predict(X_test)}).to_csv(\"./results/results_etc.csv\", index=None)\n",
    "pd.DataFrame({\"PhraseId\": PhraseId, \"Sentiment\": clf_ada.predict(X_test)}).to_csv(\"./results/results_ada.csv\", index=None)\n",
    "pd.DataFrame({\"PhraseId\": PhraseId, \"Sentiment\": clf_gtb.predict(X_test)}).to_csv(\"./results/results_gtb.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100building tree 2 of 100\n",
      "\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  7.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed: 20.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100building tree 1 of 100\n",
      "\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 10.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed: 29.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      198355.8416          101.60m\n",
      "         2      194342.9795           88.31m\n",
      "         3      192879.7697           82.13m\n",
      "         4      192112.5930           79.51m\n",
      "         5      194134.6902           77.12m\n",
      "         6 145881052654.5818           75.65m\n",
      "         7 23660709933723.9492           74.64m\n",
      "         8 23662450644206.6133           73.68m\n",
      "         9 23662450644346.7852           72.84m\n",
      "        10 23937226108178.2109           72.26m\n",
      "        11 23937226107654.5000           71.45m\n",
      "        12 23937226102165.3711           70.79m\n",
      "        13 23937226101661.3438           70.14m\n",
      "        14 23937226101263.6406           69.21m\n",
      "        15 23937226100948.9297           68.31m\n",
      "        16 23937226100539.7656           67.79m\n",
      "        17 23937226100188.0547           67.11m\n",
      "        18 23937226099798.1367           66.14m\n",
      "        19 23937226099381.9141           65.34m\n",
      "        20 23937226099075.5430           64.56m\n",
      "        21 23937226098745.4414           63.75m\n",
      "        22 23937226098425.7578           62.97m\n",
      "        23 23937226098115.0273           62.11m\n",
      "        24 23937226097858.5547           61.34m\n",
      "        25 23937226097809.2695           60.55m\n",
      "        26 23937228163663.6094           59.73m\n",
      "        27 23937246582812.5273           59.04m\n",
      "        28 23937246582616.1055           58.16m\n",
      "        29 23937246582439.0781           57.33m\n",
      "        30 23937246582263.4492           56.73m\n",
      "        31 23937246582083.9531           55.98m\n",
      "        32 23937246581935.4648           55.27m\n",
      "        33 23937246581748.5156           54.49m\n",
      "        34 86290560413184.1562           53.65m\n",
      "        35 86290560413055.4375           52.80m\n",
      "        36 86290560412923.7969           51.97m\n",
      "        37 86290560412800.7031           51.15m\n",
      "        38 86290560412692.5781           50.31m\n",
      "        39 86290560412548.2812           49.47m\n",
      "        40 86290560412426.9375           48.60m\n",
      "        41 86290560412303.8594           47.77m\n",
      "        42 86290560412188.6406           46.87m\n",
      "        43 86290560412053.7031           45.96m\n",
      "        44 86290560411939.3281           45.08m\n",
      "        45 86290560411862.0625           44.25m\n",
      "        46 86290560411781.0938           43.44m\n",
      "        47 86290560411707.2812           42.62m\n",
      "        48 86290560411632.5000           41.84m\n",
      "        49 86290560411555.0469           41.03m\n",
      "        50 86290560411474.5781           40.22m\n",
      "        51 86290560411395.0312           39.38m\n",
      "        52 86290560411319.5469           38.55m\n",
      "        53 86290560411246.8125           37.69m\n",
      "        54 86290560411166.5938           36.86m\n",
      "        55 86290560411095.0781           36.11m\n",
      "        56 86290560411025.5156           35.31m\n",
      "        57 86290560410948.1719           34.51m\n",
      "        58 86290560410879.9688           33.73m\n",
      "        59 86290560410808.2344           32.89m\n",
      "        60 86290560410745.4219           32.07m\n",
      "        61 86290560410677.8125           31.24m\n",
      "        62 86290560410610.4531           30.41m\n",
      "        63 86290560410546.7344           29.58m\n",
      "        64 86290560410477.7344           28.73m\n",
      "        65 86290560410411.3438           27.92m\n",
      "        66 86290560410344.2969           27.10m\n",
      "        67 86290560410281.8281           26.31m\n",
      "        68 86290560410221.9219           25.50m\n",
      "        69 86290560410144.3125           24.71m\n",
      "        70 86290560410082.3906           23.94m\n",
      "        71 86290560410018.5938           23.18m\n",
      "        72 86290560409959.0938           22.41m\n",
      "        73 86290560409895.8906           21.61m\n",
      "        74 86290560409839.4219           20.82m\n",
      "        75 86290560409778.4844           20.05m\n",
      "        76 86290560409711.1875           19.25m\n",
      "        77 86290560409643.8125           18.45m\n",
      "        78 86290560409584.5000           17.64m\n",
      "        79 86290560409529.5156           16.84m\n",
      "        80 86290560409477.5312           16.03m\n",
      "        81 86290560409416.9688           15.23m\n",
      "        82 86290560409309.2969           14.43m\n",
      "        83 86290560409245.5156           13.62m\n",
      "        84 86290560409191.5625           12.81m\n",
      "        85 86290560409136.9531           12.00m\n",
      "        86 86290560409099.8594           11.20m\n",
      "        87 86290560409066.4219           10.38m\n",
      "        88 86290560409032.6562            9.56m\n",
      "        89 86290560408997.8281            8.75m\n",
      "        90 86290560409000.0625            7.95m\n",
      "        91 86290560408968.4531            7.15m\n",
      "        92 86290560408936.7812            6.35m\n",
      "        93 86290560408872.8594            5.55m\n",
      "        94 86290560408838.3281            4.75m\n",
      "        95 86290560408803.8281            3.95m\n",
      "        96 86290560408771.6875            3.16m\n",
      "        97 86290560408740.1406            2.37m\n",
      "        98 86290560408707.8281            1.58m\n",
      "        99 86290560408677.2656           47.37s\n",
      "       100 86290560408644.2031            0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:   13.5s finished\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/results/results_ens.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-488aa9527a86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                            voting='hard')\n\u001b[1;32m      5\u001b[0m \u001b[0mclf_ens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"PhraseId\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPhraseId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sentiment\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclf_ens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./results/results/results_ens.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1401\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1403\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1576\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m                                      compression=self.compression)\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/results/results_ens.csv'"
     ]
    }
   ],
   "source": [
    "# Ensembling the models\n",
    "\n",
    "clf_ens = VotingClassifier(estimators=[('rf', clf_rf), ('etc', clf_etc), ('ada', clf_ada), ('gtb', clf_gtb)], \n",
    "                           voting='hard')\n",
    "clf_ens.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    9.6s finished\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    9.5s finished\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({\"PhraseId\": PhraseId, \"Sentiment\": clf_ens.predict(X_test)}).to_csv(\"./results/results_ens.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69851339228501863"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = accuracy_score(y_train, clf_ens.predict(X_train))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.77133794694348323"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = accuracy_score(y_train, clf_rf.predict(X_train))\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
